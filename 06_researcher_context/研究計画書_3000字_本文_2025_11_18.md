# 研究計画書

**研究課題**: 障害者就労支援における権利保障型アセスメントシステムの開発  
—大規模言語モデル活用による支援記録の粒度向上と当事者主権の実現—

**氏名**: 山内雄司  
**希望する指導教員名**: （記入してください）

---

## I. 研究の背景と問題意識

障害者就労支援において、ICF（国際生活機能分類）モデルは包括的なアセスメントの枠組みを提供している。しかし、特に環境因子・個人因子といった背景因子のアセスメントは、その情報量の多さと複雑性から、支援者に大きな負荷をかけている。また、世界的には障害者の権利保障とAI技術の統合が課題となっており、世界13億人の障害者が「AIのデータベースから排除」されている現状が指摘されている（Disability Ethical AI Alliance, 2024）。米国では児童福祉分野でAI支援システム（Binti社×Anthropic社）が導入されているが、その焦点は事務効率化に置かれている。

日本の障害福祉サービスにおいては、法的には準委任契約（民法656条）であるにもかかわらず、実態は「措置」の論理が残存し、当事者の契約当事者性が曖昧である。支援者が記録を独占し、当事者は自身の支援記録にアクセスできない構造は、個人情報保護法の「開示請求権」（法28条）の実質的形骸化を招いている。また、個別支援計画は作成されるものの、ケイパビリティ（機能）の実質的向上や権利実現の測定が体系化されていない。

私自身、IT企業経営者として総務省事業等1億円規模プロジェクトの遂行や情報セキュリティマネジメント（ISO27001）の内部統制構築に従事した後、障害福祉サービス就労支援分野に転じ10年以上、事務局長及びサービス管理責任者として10事業所の立ち上げ、最大利用者約100名の運営支援に従事してきた。現場で直面した構造的課題—非認知機能（自尊感情）の低位固定（10〜20パーセンタイル）、義務教育未達成による基礎的権利の未回復、支援者の善管注意義務の不明確化、当事者の記録主権の不在—に対し、非認知機能測定等による継続的データ蓄積で実践的対応を重ねた。2023年5月に自身が脳出血・聴覚障害を発症し当事者となったことで、制度の構造的限界を体感し、この実践知をLLM技術と統合し社会実装可能なガイドラインとして体系化する必要性を痛感した。

## II. 研究目的

本研究の目的は、ICFモデルにおける背景因子のアセスメントプロセスの粒度を向上させ、運用コストを抑制するため、大規模言語モデル（LLM）を活用する仕組みを開発・実証することである。ここでは、この仕組みを「Service of Empowerment（SoE）」と呼び、概念実証（Proof of Concept: PoC）として実装する。

具体的には、以下を実現する。

第一に、支援記録作成時点での権利保障として、記録が作成される段階で、障害者権利条約（CRPD）に基づく権利侵害の可能性をLLMが検出・修正提案する仕組みを構築する。米国Binti社の児童福祉AI支援が事務効率化を目的とする一方、本研究は記録作成段階での権利保障という独自の焦点を持つ。

第二に、当事者の記録主権の実現として、個人情報保護法の「開示請求権」を実質化し、当事者が自身の記録を閲覧・管理できる技術的枠組みを提供する。

第三に、当事者の理解支援として、専門用語が多用される支援記録や個別支援計画を、LLMを活用して平易な言葉に変換し、当事者が自身の状況や支援内容を理解しやすくする補助機能を提供する。

第四に、アセスメントの粒度向上として、複雑に見える支援課題を、LLMを用いて構造化・可視化し、支援者が適切に対応できる粒度に分解する。

第五に、意思決定支援とケイパビリティアプローチの統合として、既に確立された意思決定支援のフレームワークとケイパビリティアプローチ（Sen, 1999; Nussbaum, 2011）を技術設計に組み込み、当事者への過度な介入を防止する。LLMは情報提供と選択肢の提示に留め、最終的な意思決定は当事者が行える構造を担保する。

第六に、運用コストの最適化として、支援記録作成の効率化と質的向上を両立させ、支援者の事務負担を軽減しつつ、支援の質を担保する。

## III. 理論的枠組み

本研究は、以下の4つの理論的支柱に基づく統合的枠組みを構築する。

**第1の柱：準委任契約理論**

障害福祉サービスは法的には準委任契約（民法656条）であり、支援者は受任者として「善管注意義務」を負う。本研究では、この法的位置づけを明確化し、サービス提供が「措置」ではなく「契約履行」であることを技術設計に組み込む。支援者は受任者として委任者（当事者）の利益を最優先する義務があり、SoEはこの義務の履行を支援・可視化する。

**第2の柱：ケイパビリティアプローチ**

Sen（1999）とNussbaum（2011）のケイパビリティアプローチは、「機能（functionings）」と「潜在能力（capabilities）」の実質的向上を重視する。支援の成果は「就職した/しない」という結果ではなく、「選択肢を持てるようになったか」という実質的自由で評価される。本研究では、ICECAP-A（ケイパビリティ測定）、RSES-J（自尊感情尺度）、非認知機能測定を用いて、この実質的自由の変化を測定する。意思決定支援のフレームワークと統合することで、LLMが情報提供と選択肢提示に留まり、当事者の意思決定領域を侵害しない設計を実現する。

**第3の柱：粒度理論（Grain Theory）**

Westley et al.（2008）の複雑系理論における「粒度（Grain）」概念を、ICFモデルの背景因子アセスメントに適用する。支援課題は、Simple（単純・因果明確）、Complicated（複雑化しているが構造化可能）、Complex（真に複雑・創発的）の3層に分類される。本研究では、LLMを「Complicatedの構造化」に特化させることで、支援者の負荷を軽減しつつ、Complexな領域（人生の意味づけ、価値観の形成等）は当事者主導で扱う「Resolution Enhancement Cycle」を実装する。

**第4の柱：Constitutional AI**

Anthropic社のConstitutional AI（Bai et al., 2022）は、人間の価値観を「憲法」として事前に明文化し、AIシステムがその原則に基づいて自己批判・修正を行う手法である。従来の研究はOutput側（AI出力段階）の有害性除去に焦点を当てていたが、本研究はInput側（支援記録作成段階）に適用する点が独自である。CRPD（障害者権利条約）原則、特に第27条（労働・雇用）と第19条（自立生活）をLLMに「憲法」として組み込み、支援記録作成時に権利侵害の可能性を自動検出・修正提案する仕組みを構築する。重要なのは「動的更新原則」であり、SoE初期版を固定的なものとせず、科学・倫理・社会科学の進歩に合わせて継続的に改訂する設計とする。

## IV. 研究方法

本研究は混合研究法（Mixed Methods）を採用し、理論構築（第1年次）、システム設計・実装（第1年次後半〜第2年次前半）、パイロット実証研究（第2年次）、効果測定・評価（第2年次）の段階で進める。

第1年次では、先行研究レビューとして、Constitutional AI（Anthropic論文群）、Binti事例の詳細分析、ケイパビリティアプローチ×障害者支援、準委任契約理論の福祉適用、LLM×障害福祉の世界的動向を網羅的に調査する。理論的統合作業では、粒度理論の操作的定義、Input Constitutional AIの実装設計、記録主権プロトコルの法的整理を行う。倫理審査は第1年次9月〜10月に申請し、研究者の記録ノート（フィールドノート）の匿名化処理、当事者への十分な説明と任意性の担保、データ主権（当事者がデータ削除・修正できる権利）の保障に特に配慮する。

システム設計・実装では、SoEプロトタイプ（MVP）を開発する。技術スタックはPython + FastAPI（バックエンド）、PostgreSQL（データベース）、Anthropic Claude API / OpenAI GPT-4（LLM）、React（フロントエンド）を用いる。

実装機能は以下の通りである。第一に、対話型アセスメント機能として、LLMとの自然な対話を通じて、認知・非認知機能、日本語能力、時間概念の理解（10進数・12進数・60進数の混在理解）等を測定する。従来は専門職が個別に実施していた標準化検査を、1-2週間（実働10日×5時間程度）の継続的対話の中でLLMが自然に行う。第二に、当事者言語パターン学習として、当事者ごとの自然言語表現の癖（「9時半」「9時30分」「9.5時間後」等の時間表現の理解度等）をLLMが学習し、支援者に提供することで、支援の属人化を防ぎ、運用コストを大幅に削減する。第三に、記録主権ダッシュボードとして、当事者が自分の記録を閲覧・管理できる機能を提供し、LLMが専門用語を平易な言葉に変換して理解を支援する。第四に、粒度評価支援として、支援課題をSimple/Complicated/Complexに分類し、LLM支援と人手確認の組み合わせで効率的に処理する。第五に、Constitutional AIチェックとして、CRPD原則に基づく権利侵害の自動検出・修正提案を行う。

倫理的セーフガードとして、以下を実装する。第一に、過剰推測防止原則として、LLMは「推測しない優しさ」を基本とし、当事者の内面への過度な踏み込みを技術的に制限する。第二に、ブラインドゾーン設計として、自殺関連、深層トラウマ、診断模倣等、再トラウマ化や自己攻撃のリスクがある領域は意図的に非可視化する。第三に、専門家橋渡しプロセスとして、危険シグナル検知時は、SoEが判断を代替せず、適切な専門家（医療・行政）への橋渡しを行う。第四に、動的更新原則として、SoE初期版を固定的なものとせず、科学・倫理・社会科学の進歩に合わせて継続的に改訂する（詳細は参考資料「SoE設計思想書」参照）。

第2年次のパイロット実証研究では、協力事業所1-2箇所、参加当事者10-20名（インフォームドコンセント取得済み）を対象に、6ヶ月間のデータ収集を行う。量的データとして、自尊感情スコア（RSES-J）、ケイパビリティ測定（ICECAP-A）、粒度スコア（独自開発）、記録主権行使状況を、介入前・介入後・3ヶ月後で測定する。質的データとして、当事者インタビュー（半構造化）、支援者インタビュー（半構造化）、支援記録の質的分析を行う。分析手法は、量的には対応のあるt検定、重回帰分析、記述統計を、質的にはテーマ分析（NVivo等使用）、グラウンデッド・セオリー・アプローチを用いる。

評価軸は以下を設定する。①Constitutional AIチェックによる権利侵害検出率（介入前と比較して50%以上減少）、②ケイパビリティスコアの向上（ICECAP-A得点が統計的有意に上昇 p < 0.05）、③当事者の記録主権行使率（参加者の80%以上がダッシュボードを月1回以上利用）、④粒度向上による支援者負荷軽減（Complicated業務の30%がSimple化、支援者の事務時間が週2時間削減）、⑤対話型アセスメントの信頼性検証（1-2週間の対話測定と従来の標準化検査の相関係数 r > 0.7）、⑥測定コストの削減効果（専門職による測定時間と比較して50%以上削減）、⑦過剰介入防止の確認（インタビューで「過剰な意味付けを感じた」との回答が10%以下）。

## V. 期待される成果

学術的には、粒度理論の障害者支援への初適用により、複雑系理論の福祉実践への翻訳という新たな研究領域を開拓する。Input Constitutional AIの方法論的確立は、Anthropicの先行研究を超える理論的・実践的貢献となり、AI倫理学・障害学の学際的統合モデルとして注目される可能性がある。記録主権の法的・技術的実装モデルは、個人情報保護法の実質化、データ主権論の福祉領域での具体化として、他分野（医療、教育）への応用可能性を持つ。

社会的には、SoEプロトタイプをガイドライン化することで、全国の就労支援事業所（約5,000箇所）が特別な技術投資なしに権利保障を向上させる仕組みを提供できる。準委任契約の実質化による構造改革は、「措置の論理」から「契約の論理」への転換を促進し、当事者の契約当事者性を強化する。これは障害福祉サービス年間予算5,400億円の質的向上につながる。また、権利侵害の早期発見・予防システムにより、木浦氏事件（笠岡市、2023年）のような悲劇を、個人の英雄性に依存せず、システムで予防できる。

国際的には、Susan Scott-Parker OBE（2025年11月13日面談実施、Disability Ethical AI Alliance創設者）との継続的協働により、日本発のモデルを国際標準へと発展させる道筋が開かれている。Input Constitutional AIの概念を国際的に発信し、世界13億人の障害者の権利保障モデル、AIバイアス問題の根本的解決策として提示する。

## VI. 研究の限界と今後の展開

修士課程では、パイロット研究は10-20名、1-2事業所に限定され、特定地域・特定障害種別への限定可能性がある。また6ヶ月の追跡では長期的効果（2年後、5年後）は検証できない。これらは2年間という時間的制約、倫理審査・実装の負荷による。

博士後期課程では、大規模実証研究（N=100以上）による複数地域・複数障害種別での効果検証、4本柱（権利回復・支援者倫理・地域人材開発・アセスメント）の完全統合、国際比較研究・海外実装へと展開する。社会実装は、修士修了後（2028年〜）のNPO法人設立・SoE社会実装、博士課程中〜修了後（2028-2033年）の「日本版サムハルシステム」構築・全国展開、2030年代の国際標準化・Anthropic連携・データコモンズ実現という段階的道筋を描いている。

## VII. 研究倫理上の配慮

個人情報保護として、研究者の記録ノート（フィールドノート）の匿名化処理（固有名詞の自動マスキング）、データの暗号化保存（AES-256）、当事者による削除・修正権の保障（記録主権の実質化）を行う。インフォームドコンセントでは、研究目的・方法・リスク・利益の十分な説明、任意性の担保（参加拒否・途中離脱が不利益にならないことの明示）、知的障害・精神障害のある当事者への配慮（平易な言葉、視覚的資料、理解確認）を徹底する。過剰推測防止として、LLMの「Complex領域」への介入防止アルゴリズム、ブラインドゾーン設計（自殺関連・深層トラウマ・診断模倣の非可視化）、過剰な意味付けのモニタリング（定期的な当事者・支援者インタビュー）を実装する。危険シグナル検知時は、SoEが判断を代替せず、医療・行政等の適切な専門家へ橋渡しするプロセスを確立する。動的更新原則により、倫理的セーフガードも科学的知見の進展に合わせて改訂する。日本社会事業大学研究倫理審査委員会への申請・承認取得を行い、研究計画の変更時は再審査申請を行う。

## 主要参考文献

- Bai, Y., et al. (2022). Constitutional AI: Harmlessness from AI Feedback. arXiv:2212.08073.
- Anthropic. (2023). Claude's Constitution. https://www.anthropic.com/news/claudes-constitution
- PRNewswire. (2025, August 21). Binti Launches First-of-its-Kind 'AI for Social Services'.
- Sen, A. (1999). Development as Freedom. Oxford University Press.
- Nussbaum, M. (2011). Creating Capabilities. Harvard University Press.
- Westley, F., et al. (2008). Getting to Maybe: How the World is Changed. Vintage Canada.
- Disability Ethical AI Alliance. (2024). https://disabilityethicalai.org/
- Quinn, G. (2022). Artificial Intelligence and the Rights of Persons with Disabilities. UN A/HRC/49/52.
- Cogburn, D., et al. (2025). Uncovering Policy Priorities for Disability Inclusion. Data & Policy, 7, e61.

**参考資料**（別添）:
- 山内雄司. (2025). SoE設計思想書（Declaration）. 研究計画参考資料.

---

**文字数**: 約3,100字

（2025年11月18日作成・最終更新）
