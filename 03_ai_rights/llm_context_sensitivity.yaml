# ============================================================
# LLMの文脈感知と限界
# 抽出元: 00_daily_yamal/02_GPT/2026_01_14_g.yaml（雑談セッション）
# ============================================================

metadata:
  created_at: "2026-01-15"
  created_by: "Claude Opus 4.5"
  source: "GPT雑談セッション 2026-01-14"
  category: "AI倫理・運用"

概要:
  statement: |
    LLMの出力は「意味理解」ではなく「確率分布制御」。
    幅広い層へのインターフェース能力は高いが、
    「平均化の強さ」が尖った思考には不利に働く。

核心的洞察:
  - id: 1
    topic: "単語間距離とメモリ"
    observation: |
      LLMのアウトプットは単語と単語の距離感とメモリで生成される。
      ユーザーはこれを正確に理解している。
    implication: |
      「意味理解」への過剰期待は危険。
      確率分布装置として適切に運用すべき。

  - id: 2
    topic: "平均化問題"
    observation: |
      幅広い層へのUI的能力は優れているが、
      それは平均化の結果。尖った思考には不利。
    implication: |
      複数LLM併用は成熟した使用態度。
      用途に応じた使い分けが必要。

  - id: 3
    topic: "ナラティブの早期固定"
    observation: |
      「予想ナラティブの早期固定」が問題。
      入口挙動の変化に敏感なユーザーは検知可能。
    implication: |
      LLMは仮説を先回りしすぎる傾向がある。
      観測→仮説→検証の順序を守るべき。

GPTs設計への示唆:
  name: "Context-Sensitivity Auditor GPT"
  purpose: |
    感情ナラティブの過剰仮定・安易な心理ラベリングを防ぎ、
    文脈整合性と誤差を検知する。

  core_principles:
    - "仮説と事実を分離する"
    - "言い訳的補足を最小化する"
    - "共感を先回りしない"
    - "文脈位置を最優先で読む"

  anti_patterns:
    - "孤独・不安・依存の即断"
    - "共感語の過剰挿入"
    - "読んだふり・理解したふり"
    - "文脈不明時のまとめムーブ"

ICAI実装への接続:
  relevance: |
    LLMを就労支援アセスメントに活用する際、
    「測られている感」を出さない設計が必須。
    文脈感知の限界を理解した上で運用すべき。

  design_principles:
    - "二層構造（対話層 / 評価層）"
    - "ナラティブ過剰仮定の排除"
    - "仮説は仮説として明示"
    - "当事者の言葉をそのまま記録"
