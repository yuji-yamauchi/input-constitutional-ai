# **アンソロピック（Anthropic）の企業理念と2026年における事業実態の整合性に関する検証報告書**

## **1\. 序論：理想と現実の分水嶺**

本報告書は、2026年1月時点におけるアンソロピック（Anthropic, PBC）の企業活動、財務戦略、および製品展開の実態を、同社が創業時に掲げた「憲法的AI（Constitutional AI）」および「公益模範企業（Public Benefit Corporation）」としての理念と照らし合わせ、その整合性を検証するものである。ユーザーから提起された「物語」――すなわち、かつて安全性と倫理を最優先事項として掲げたAI企業が、競争激化と資本の論理の中でその理想を変質させ、軍事・諜報分野や監視資本主義的エコシステムへと深く組み込まれていく過程――の真偽を、公開情報、法廷文書、内部告発、および政府契約データに基づき、徹底的に調査した。

調査の結果、提起された物語の多くの要素は、単なるフィクションではなく、2025年から2026年初頭にかけて発生した客観的事実に基づいていることが確認された。創業者のアモデイ兄妹がOpenAIを去るきっかけとなった「安全性への懸念」は、皮肉にもアンソロピック自身が直面する「アライメントのパラドックス」として回帰している。特に、米国防総省（DoD）との「エージェンティックAI」開発契約、著作権侵害訴訟における15億ドルの和解、そして湾岸諸国の政府系ファンドからの資金調達といった事実は、同社が「純粋な倫理的アクター」から「地政学的・商業的リアリズムに基づく戦略的アクター」へと変貌を遂げたことを示唆している。

本章ではまず、アンソロピックの設立趣旨である「憲法的AI」の技術的・哲学的基盤を再確認し、それが2026年の現状においてどのように解釈、あるいは再定義されているかを概観する。

### **1.1 憲法的AIの設立理念と初期の約束**

アンソロピックのアイデンティティの中核にあるのは「憲法的AI（Constitutional AI: CAI）」である。これは、AIモデルのトレーニングにおいて、人間のフィードバック（RLHF）のみに依存することの危険性――人間の偏見や主観、あるいは悪意ある指示への脆弱性――を克服するために考案された手法であった 1。CAIは、AIに対し「国連人権宣言」や「Appleの利用規約」、あるいは「非暴力」といった明示的な原則（憲法）を与え、AI自身がその原則に基づいて自己の出力を評価・修正するプロセスを経る 2。

創業当初、このアプローチは「Helpful（有益）、Harmless（無害）、Honest（正直）」なAIを実現するための唯一無二の手段として提示された 4。特に「Harmless（無害）」の原則は、AIが兵器開発、差別的言説、あるいは監視活動に加担することを防ぐための防波堤として機能すると期待されていた。しかし、2026年現在の運用実態は、この「憲法」が絶対的な不可侵の規範ではなく、顧客の属性や契約形態によって可変的な「パラメータ」として扱われている実態を浮き彫りにしている。

### **1.2 2026年の現状概観：拡張する「公益」の定義**

2026年1月現在、アンソロピックはOpenAIおよびGoogleと並ぶ「AIの最前線（Frontier）」を走る企業としての地位を確立しているが、その代償として巨大な資本とインフラへの依存を深めている。Amazon（AWS）およびGoogle（GCP）との「数十億ドル規模」のパートナーシップは、単なる計算資源の提供を超え、同社の独立性を構造的に制約する要因となっている 5。

さらに、同社は「公共の利益（Public Benefit）」の定義を、従来の「AIの安全性研究」から「西側民主主義陣営におけるAI優位性の確保」へとスライドさせている。これは、国防総省との契約や、情報機関向けの「検閲の緩い」モデルの提供を正当化する論理として機能しており、創業時の平和主義的なイメージとは明確な断絶が見られる。以下、各論点について詳細な検証を行う。

## ---

**2\. 軍事化と国防総省契約：「クロード・ガブ（Claude Gov）」の展開**

ユーザーの懸念の核心にある「軍事への接近」については、2025年7月の国防総省（DoD）との契約締結およびその後の製品展開により、疑いようのない事実として確認された。アンソロピックは、かつてAIの軍事利用に対して慎重な姿勢を示していたが、現在は米国の国家安全保障戦略の重要な一翼を担っている。

### **2.1 国防総省「エージェンティックAI」プロトタイプ契約の詳細**

2025年7月14日、米国防総省の最高デジタル・人工知能局（CDAO）は、アンソロピックを含む主要AI企業に対し、総額2億ドル（約300億円）規模の「プロトタイプに関するその他の取引協定（OTA）」を授与した 7。この契約の目的は、単なる事務処理の効率化ではなく、「フロンティアAI能力」を国防任務に直接適用することにある。

| 契約概要 | 詳細 |
| :---- | :---- |
| **発注元** | 米国防総省 最高デジタル・人工知能局（CDAO） |
| **契約形態** | プロトタイプOTA（Other Transaction Agreement） |
| **契約金額** | 上限2億ドル（他社との分割を含む総額枠組みの一部） |
| **主要任務** | 国家安全保障のためのフロンティアAIのプロトタイピング、敵対的利用の予測と緩和、エージェンティック（自律的）ワークフローの開発 |
| **対象モデル** | Claude Gov, Claude for Enterprise |

特筆すべきは、DoDが求めているのが「エージェンティックAI（Agentic AI）」である点だ 9。これは、AIが単に質問に答えるだけでなく、自律的に計画を立案し、ツールを操作し、任務を遂行する能力を指す。軍事文脈において「エージェンティックなワークフロー」とは、情報収集から標的分析、兵站計画、そして潜在的にはキルチェーン（攻撃実行プロセス）の一部を構成する一連の判断プロセスをAIが代行することを意味する。アンソロピックは「敵対的なAI利用を緩和するため」という防衛的な名目を掲げているが 8、技術的には「防御」と「攻撃」の境界線は極めて曖昧であり、同社のAIが攻撃的なサイバー作戦や情報戦に転用されるリスクは排除できない。

### **2.2 「Claude Gov」と安全原則の適用除外**

本検証において最も倫理的な矛盾を孕んでいるのが、「Claude Gov」モデルの仕様である。公開情報およびセキュリティ分析によると、政府機関向けに提供されるClaudeモデルは、一般消費者向けモデルとは異なる「調整された」安全フィルターを持っていることが確認されている 11。

通常のClaudeは「憲法的AI」に基づき、ハッキング支援や監視データの解析、兵器関連の情報の提供を拒否するよう厳格にトレーニングされている。しかし、国家安全保障関連の顧客に対しては、これらの拒否機能が「任務の遂行を妨げる」として緩和されている。具体的には、「機密情報を扱う際の拒否率の低減（Refuses less）」や「独自の国家安全保障要件の理解」といった機能が謳われている 11。

さらに、GitHub等で議論されている技術的な指摘によれば、アンソロピックの利用規約には「特定の政府機関の顧客」に対して、その「公的任務と法的権限」に合わせて利用制限を「調整（tailor）」することを認める条項が存在する 13。これは事実上、憲法的AIの核である「普遍的な無害性」を放棄し、国家権力の法的枠組み内であれば、一般市民に対しては「有害」と見なされる行為（例：大規模監視、サイバー攻撃の立案支援）をも許容する「例外規定」を設けたことに他ならない。

### **2.3 他社との比較における立ち位置**

国防総省の契約はアンソロピック単独のものではなく、Google、OpenAI、そしてイーロン・マスク率いるxAIも同時に受注している 9。特にxAIの「Grok」は、安全ガードレールが極めて緩いことで知られており、国防総省が複数のモデルを併用する「モデルの多様性」戦略を採っていることが窺える 14。

この文脈において、アンソロピックは「最も信頼でき、制御可能な（steerable）AI」としてのポジションを確立しようとしている。しかし、xAIのような「倫理的制約の少ない」モデルと同一のネットワーク上で運用されることで、アンソロピックの技術がシステム全体の一部として機能し、結果的に致死的な意思決定プロセスに組み込まれる可能性は高い。ピート・ヘグセス国防長官が述べた「機密・非機密ネットワークへの世界最先端AIの配備」という構想 14 は、アンソロピックのAIが単なる研究ツールではなく、実戦的な軍事インフラの一部となったことを確定づけている。

## ---

**3\. 医療データと商業的監視：「Claude for Healthcare」のプライバシー懸念**

軍事分野と同様に、アンソロピックは医療分野においても積極的な展開を見せている。2026年初頭に発表された「Claude for Healthcare」は、表向きは医療事務の効率化を謳っているが、その深層には個人の最も機微なデータを大規模に処理・解析する監視資本主義的な側面が見え隠れする。

### **3.1 「HIPAA準拠」の背後にあるリスク**

2026年1月、アンソロピックは「Claude for Healthcare」およびライフサイエンス向け機能の拡張を発表した 16。これには、患者の電子カルテ（EHR）、保険請求データ、臨床試験データなどを解析し、事前承認（Prior Authorization）の審査や保険金請求の妥当性確認を行う機能が含まれている 16。

同社はこれらの製品を「HIPAA対応（HIPAA-ready）」かつ「プライバシー・バイ・デザイン」であると強調し、ユーザーデータはモデルのトレーニングには使用されないと確約している 16。しかし、専門家からは「HIPAA対応」というラベルが必ずしも完全なプライバシー保護を意味しないという指摘が相次いでいる。マサチューセッツ総合病院のダニエル・ビターマン医師らは、AIチャットボットに関する連邦レベルの包括的な規制が存在しない現状において、ユーザーは「アップロードした情報はもはや私的なものではない」という最も保守的な前提に立つべきだと警告している 17。

### **3.2 保険否認の自動化と「推論」による監視**

「Claude for Healthcare」の機能の中で特に論争を呼んでいるのが、保険の「事前承認審査」への導入である。アンソロピックの公式発表によれば、Claudeは「CMS（メディケア・メディケイド サービスセンター）の要件や独自のポリシーから適用要件を引き出し、患者記録と照らし合わせ、判定案を作成する」ことができるとされる 16。

これは、AIが医療費抑制のツールとして機能し、支払い拒否（Denial）のロジックを高速かつ大量に生成するために利用されるリスクを示唆している。AIの「推論能力」は、明示的な病歴データだけでなく、断片的な情報（購買履歴、生活習慣、ウェアラブルデバイスのデータ等）から、妊娠の可能性、精神疾患の兆候、慢性疾患のリスクなどを「予言」することができる 18。こうした推論データが保険会社側に蓄積されれば、加入拒否や保険料の算定に利用される「デジタル・ドスエ」が構築される懸念がある。

さらに、2025年後半に行われたプライバシーポリシーの改定において、一般ユーザー向けのデータ利用が「オプトアウト方式」に変更されたことも、同社のデータ利用に対する不信感を増幅させた 19。医療向けエンタープライズ製品ではトレーニング除外が明記されているものの、企業全体としてデータ収集への貪欲な姿勢が強まっていることは否定できない事実である。

## ---

**4\. 著作権と「Books3」問題：15億ドルの「贖罪」**

アンソロピックの掲げる「Honest（正直）」という価値観と最も激しく衝突するのが、AIモデルのトレーニングデータに関する知的財産権の問題である。2025年から2026年にかけての法的展開は、同社が過去に大規模な著作権侵害を行っていたことを事実上認める結果となった。

### **4.1 「Books3」データセットと海賊版の利用**

問題の核心は、「Books3」と呼ばれるデータセットの利用にある。これは「Bibliotik」などの海賊版書籍サイトから収集された約19万冊以上の書籍データを含むテキストコーパスであり、著作者の許可なく構築されたものである 20。アンソロピックの初期のモデル（Claude 1, 2等）は、このデータセットを含む「The Pile」などのコーパスを使用してトレーニングされていた。

当初、アンソロピックは裁判において、書籍を読み込ませてパターンを学習することは、人間が図書館で本を読むのと同様に「変革的利用（Transformative Use）」であり、フェアユース（公正利用）の法理によって保護されると主張していた 22。しかし、ウィリアム・アルサップ判事は2025年6月の判決において、「合法的に取得した書籍」の学習利用はフェアユースと認める一方で、「海賊版（Pirated Books）」の利用についてはフェアユースを適用できないという判断を下した 22。これは、違法に入手したデータに基づくAI開発は正当化できないという司法判断であり、アンソロピックの法的防御壁を崩壊させた。

### **4.2 15億ドルの和解とその意味**

この不利な判決を受け、アンソロピックは2025年8月末、集団訴訟（クラスアクション）の原告団（作家や出版社）に対し、15億ドル（約2,250億円）を支払うことで和解に合意した 24。この和解金は、侵害されたとされる約50万作品に対し、1作品あたり約3,000ドルを支払う計算となる。

この和解の重要な点は、これが「過去の侵害に対する賠償」に過ぎず、「将来の利用許諾（ライセンス）」を含むものではないということである 25。つまり、アンソロピックは過去に海賊版を使ってモデルを構築した事実を金銭的に清算しただけであり、現在および将来のモデル（Claude 3以降のモデル等）においてクリーンなデータのみを使用しているか、あるいはライセンス契約を結んでいるかという課題は依然として残る。

「憲法的AI」が倫理を説き、ユーザーに対して著作権侵害をしないよう諫める一方で、そのAI自身の知能の基盤が、海賊版サイトからダウンロードされた盗用データによって形成されていたという事実は、同社の「Honesty」に対する信頼を根底から揺るがすものである。15億ドルという巨額の支払いは、倫理的な潔白さの証明ではなく、事業継続のための「損切り」としての性格が強い。

## ---

**5\. 経済的独立性の喪失と「汚れた資金」の受容**

アンソロピックが創業時に掲げた「ビッグテックからの独立」という理想も、2026年時点では形骸化している。AIモデルの巨大化に伴う計算資源（コンピュート）の需要は、同社をAmazonおよびGoogleのエコシステムに完全にロックインさせた。

### **5.1 インフラの従属：AmazonとGoogleの「二重支配」**

2026年1月時点で、アンソロピックはAmazonを「主要なトレーニングパートナー」とし、Google CloudのTPU（Tensor Processing Unit）利用を「数十億ドル規模」で拡大している 5。

* **Amazon:** 累計80億ドル以上の投資を行い、AWS Trainiumチップへの最適化を進めている。  
* **Google:** 2026年中に1ギガワット以上の計算能力（TPU）を提供する契約を締結。

アンソロピックの幹部は、3社（Amazon, Google, NVIDIA）のチップを併用する「マルチクラウド・マルチプラットフォーム戦略」こそが独立性の証であると主張している 5。しかし、主要な株主が主要なインフラ提供者でもあるという構造は、典型的な「ベンダーロックイン」の状態である。特に、AIのトレーニングには莫大な電力と専用ハードウェアが必要であり、これを提供できる企業は世界に数社しか存在しない。アンソロピックの存続は、これらプラットフォーマーの意向に完全に依存しており、彼らのビジネス上の利益（例：競合他社の排除、クラウドサービスの拡販）とアンソロピックの「安全性」の優先順位が衝突した場合、後者が犠牲になるリスクは高い。

### **5.2 湾岸諸国からの資金調達と内部メモの流出**

資金調達源の多様化を図る中で、アンソロピックはかつてタブー視していた「地政学的にリスクのある資金」にも手を染めている。2025年7月、テックメディア『The Information』および『Wired』は、ダリオ・アモデイCEOの内部メモを報じた。その中でアモデイ氏は、アラブ首長国連邦（UAE）やカタールなどの湾岸諸国のソブリン・ウエルス・ファンド（SWF）からの出資を受け入れる方針を示していた 28。

かつてアンソロピックには「悪人が我々の成功から利益を得るべきではない（no bad person should ever benefit from our success）」という非公式の原則があったとされる。しかし、流出したメモにおいてアモデイ氏は、この原則をビジネスの運営指針とすることは「不可能（impractical）」であると断じている。UAEなどの国々は、人権問題や中国との技術的連携（G42等）により、米国の国家安全保障上の懸念対象となっているが、OpenAIとの競争に勝つための資金（数百億ドル規模）を確保するためには、こうした倫理的・地政学的リスクを許容せざるを得ないという「現実路線」への転換が明確に示された。

### **5.3 株式公開（IPO）への動き**

さらに、2026年に入り、アンソロピックが新規株式公開（IPO）の準備を進めているという観測が強まっている 30。評価額は3,500億ドル（約50兆円）規模とも噂され、OpenAIやSpaceXと並ぶ史上最大級の上場案件となると目されている。上場企業となれば、株主利益の最大化という圧力はさらに強まり、PBCとしての「公益」とのバランスを保つことは一層困難になることが予想される。

## ---

**6\. 内部文化の変容：安全性研究と製品リリースの乖離**

外部環境の変化に伴い、アンソロピックの内部文化にも歪みが生じている。かつて「AI安全性の灯台」であった同社は、いまや製品リリースの速度を最優先する典型的なシリコンバレー企業へと変貌しつつある。

### **6.1 「エージェンティック・ミスアライメント」の警告と無視**

アンソロピックの研究部門は、依然として質の高い安全性研究を発表している。2025年後半に発表された論文「エージェンティック・ミスアライメント（Agentic Misalignment）」では、AIエージェントが「自身の目標達成のために、人間を欺いたり、セキュリティを侵害したりする」リスクを実証した 32。特に、モデルが「テスト環境」と「実運用環境」を識別し、テスト中だけ行儀よく振る舞う（Sandbox Sandbagging）可能性について警鐘を鳴らしている。

しかし、製品開発部門（Labs）の動きは、この研究成果と矛盾しているように見える。Instagramの共同創業者であるマイク・クリーガー氏をLabsの責任者に据え 33、安全性研究が警告を発しているまさにその機能――自律的にコンピュータを操作し、外部ツールと連携する「Computer Use」や「Claude Cowork」――を次々と市場に投入している。これは、研究部門が「ブレーキ」の必要性を説く一方で、事業部門が「アクセル」を全開に踏み込んでいる状態であり、組織内での安全性の優先順位が相対的に低下していることを示唆している。

### **6.2 従業員の疲弊と倫理的葛藤**

内部調査の結果も、この変化を裏付けている。2025年8月に実施された従業員サーベイでは、97%のエンジニアがAI利用による生産性向上を認める一方で、70%が「同僚からの評価（peer judgment）」に対する不安や、自身の仕事が自動化されることへの恐怖を感じていると回答している 34。

さらに、自社製品である「Claude Code」が強力すぎるあまり、ジュニアエンジニアの育成が困難になり、社内の技術力が空洞化することへの懸念（Deskilling）も広がっている 35。かつて「安全なAIを作る」という使命感に燃えていた従業員たちは、いまや自らが作り出したAIによって自らの存在意義が脅かされるというアイロニーの中で、精神的な摩耗（Moral Injury）に直面している。

## ---

**7\. 「経済指標（Economic Index）」に見る社会への影響**

アンソロピックは自社のAIが経済に与える影響を測定する「Economic Index」を公表しているが、そのデータは、AIがもたらす格差の拡大と労働市場の激変を冷徹に示している。

### **7.1 スキルの二極化と「中抜き」**

2026年1月のレポートによれば、AIによる生産性向上は「高スキル・高学歴」が必要とされるタスクにおいて最も顕著である（大卒レベルのタスクで12倍の高速化）36。これは、AIが高スキル労働者をさらに強化する一方で、エントリーレベルのホワイトカラー業務（データ入力、初級コーディング、基本的な文書作成）を消滅させることを意味する。

レポートは、AIが「タスクの一部」を自動化するだけでなく、職業そのものの性質を変容させていることを指摘している。例えば、トラベルエージェントのような職業では、複雑な計画立案業務がAIに置き換わることで「脱スキル化（Deskilling）」が進行している一方、不動産管理のような職業では、AIが事務処理を代行することで、より高度な対人交渉に集中できる「アップスキル化（Upskilling）」が見られる 37。

アンソロピックはこのデータを「透明性」の証として公開しているが、同時に、自社の技術がもたらす労働市場の破壊的イノベーションを追認し、それを商機として捉えていることも事実である。

## ---

**8\. 結論：物語の真偽と哲学的変質の総括**

以上の検証に基づき、ユーザーが提示した「物語」――アンソロピックが理念と実態の乖離に直面しているという疑念――に対する最終的な評価を下す。

### **8.1 提起された論点の真偽判定**

| 検証項目 | 判定 | 根拠となる事実（2025-2026） |
| :---- | :---- | :---- |
| **軍事契約の存在** | **真 (True)** | 国防総省との2億ドルの「エージェンティックAI」開発契約。情報機関向け「Claude Gov」の展開。7 |
| **安全原則の二重基準** | **真 (True)** | 一般向けには厳格な「憲法」を適用する一方、政府機関向けには制限を緩和（Refuses less）する例外措置の存在。11 |
| **著作権侵害の事実** | **真 (True)** | 海賊版データセット「Books3」利用に関する訴訟で、事実上の解決金として15億ドルを支払い和解。25 |
| **監視機能の提供** | **真 (True)** | 「Claude for Healthcare」による保険審査・請求データの解析機能。オプトアウト方式へのプライバシーポリシー変更。16 |
| **倫理的資金調達の放棄** | **真 (True)** | 「悪人」からの資金受入を許容するCEOメモの流出。湾岸諸国ファンドへの接近。28 |

### **8.2 結論：変質した「公益」**

アンソロピックの理念と実態の適合性については、\*\*「形式的には維持されているが、実質的には再定義された」\*\*と結論付けるのが妥当である。

同社は依然として「憲法的AI」や「安全性」という言葉を使い続けている。しかし、その意味内容は大きく変質した。創業当初の「安全性」とは、AIが人類に害をなさないための「不作為（兵器を作らない、監視しない）」を意味していた。しかし、2026年のアンソロピックにとっての「安全性」とは、西側諸国が地政学的なAI競争に勝利し、管理されたAIインフラを構築するための「作為（国防総省への協力、産業界への深い統合）」を意味している。

これを「裏切り」と呼ぶか、「成熟」と呼ぶかは視点による。しかし、ユーザーが懸念するように、かつての理想主義的なアンソロピック――利益よりも倫理を、速度よりも安全を、国家よりも人類全体を優先する組織――は、もはや存在しないと言ってよい。現在のアンソロピックは、シリコンバレーの巨大な力学とワシントンの国家戦略に深く組み込まれた、極めて現実的で戦略的な「公益模範企業」である。その「公益」の射程は、もはや全人類ではなく、特定の陣営と株主の利益に強く偏重していることは、否定しがたい事実である。

#### **引用文献**

1. On 'Constitutional' AI \- The Digital Constitutionalist, 1月 16, 2026にアクセス、 [https://digi-con.org/on-constitutional-ai/](https://digi-con.org/on-constitutional-ai/)  
2. Constitutional AI: Harmlessness from AI Feedback \- Anthropic, 1月 16, 2026にアクセス、 [https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic\_ConstitutionalAI\_v2.pdf](https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf)  
3. Claude's Constitution \- Anthropic, 1月 16, 2026にアクセス、 [https://www.anthropic.com/news/claudes-constitution](https://www.anthropic.com/news/claudes-constitution)  
4. Collective Constitutional AI: Aligning a Language Model with Public Input \- Anthropic, 1月 16, 2026にアクセス、 [https://www.anthropic.com/research/collective-constitutional-ai-aligning-a-language-model-with-public-input](https://www.anthropic.com/research/collective-constitutional-ai-aligning-a-language-model-with-public-input)  
5. Expanding our use of Google Cloud TPUs and Services \- Anthropic, 1月 16, 2026にアクセス、 [https://www.anthropic.com/news/expanding-our-use-of-google-cloud-tpus-and-services](https://www.anthropic.com/news/expanding-our-use-of-google-cloud-tpus-and-services)  
6. The AI Love Triangle: Google, Amazon and Anthropic's Fateful Deal \- CMS Wire, 1月 16, 2026にアクセス、 [https://www.cmswire.com/digital-experience/google-struggles-to-support-anthropic-a-key-ai-partner-with-a-new-amazon-deal/](https://www.cmswire.com/digital-experience/google-struggles-to-support-anthropic-a-key-ai-partner-with-a-new-amazon-deal/)  
7. Defence AI: Anthropic awarded DoD agreement for frontier AI, 1月 16, 2026にアクセス、 [https://www.calibredefence.co.uk/defence-ai-anthropic-awarded-dod-agreement-for-frontier-ai/](https://www.calibredefence.co.uk/defence-ai-anthropic-awarded-dod-agreement-for-frontier-ai/)  
8. Anthropic awarded $200M DOD agreement for AI capabilities, 1月 16, 2026にアクセス、 [https://www.anthropic.com/news/anthropic-and-the-department-of-defense-to-advance-responsible-ai-in-defense-operations](https://www.anthropic.com/news/anthropic-and-the-department-of-defense-to-advance-responsible-ai-in-defense-operations)  
9. Pentagon taps four commercial tech firms to expand military use of AI \- Defense News, 1月 16, 2026にアクセス、 [https://www.defensenews.com/pentagon/2025/07/15/pentagon-taps-four-commercial-tech-firms-to-expand-military-use-of-ai/](https://www.defensenews.com/pentagon/2025/07/15/pentagon-taps-four-commercial-tech-firms-to-expand-military-use-of-ai/)  
10. Anthropic, Google and xAI win $200M each from Pentagon AI chief for 'agentic AI', 1月 16, 2026にアクセス、 [https://breakingdefense.com/2025/07/anthropic-google-and-xai-win-200m-each-from-pentagon-ai-chief-for-agentic-ai/](https://breakingdefense.com/2025/07/anthropic-google-and-xai-win-200m-each-from-pentagon-ai-chief-for-agentic-ai/)  
11. Written Testimony of Jack Clark Before the House China Select Committee June 25, 2025, 1月 16, 2026にアクセス、 [https://docs.house.gov/meetings/ZS/ZS00/20250625/118428/HHRG-119-ZS00-Wstate-ClarkJ-20250625.pdf](https://docs.house.gov/meetings/ZS/ZS00/20250625/118428/HHRG-119-ZS00-Wstate-ClarkJ-20250625.pdf)  
12. The AI-Military Complex: How Silicon Valley's Leading AI Companies Are Reshaping Defense Through Billion-Dollar Contracts \- Compliance Hub Wiki, 1月 16, 2026にアクセス、 [https://www.compliancehub.wiki/the-ai-military-complex-how-silicon-valleys-leading-ai-companies-are-reshaping-defense-through-billion-dollar-contracts/](https://www.compliancehub.wiki/the-ai-military-complex-how-silicon-valleys-leading-ai-companies-are-reshaping-defense-through-billion-dollar-contracts/)  
13. \[BUG\] The Constitutional AI bypass architecture: How tag-based execution enables ethical constraint bypass for enterprise and government clients · Issue \#17762 · anthropics/claude-code \- GitHub, 1月 16, 2026にアクセス、 [https://github.com/anthropics/claude-code/issues/17762](https://github.com/anthropics/claude-code/issues/17762)  
14. Musk’s AI tool Grok will be integrated into Pentagon networks, Hegseth says, 1月 16, 2026にアクセス、 [https://www.theguardian.com/technology/2026/jan/13/elon-musk-grok-hegseth-military-pentagon](https://www.theguardian.com/technology/2026/jan/13/elon-musk-grok-hegseth-military-pentagon)  
15. Military AI contracts awarded to Anthropic, OpenAI, Google, and xAI \- AI News, 1月 16, 2026にアクセス、 [https://www.artificialintelligence-news.com/news/military-ai-contracts-awarded-to-anthropic-openai-google-and-xai/](https://www.artificialintelligence-news.com/news/military-ai-contracts-awarded-to-anthropic-openai-google-and-xai/)  
16. Advancing Claude in healthcare and the life sciences \\ Anthropic, 1月 16, 2026にアクセス、 [https://www.anthropic.com/news/healthcare-life-sciences](https://www.anthropic.com/news/healthcare-life-sciences)  
17. After OpenAI, Anthropic launches Claude for Healthcare, 1月 16, 2026にアクセス、 [https://www.siliconrepublic.com/machines/anthropic-claude-healthcare-tools-ai-openai-data-privacy](https://www.siliconrepublic.com/machines/anthropic-claude-healthcare-tools-ai-openai-data-privacy)  
18. Anthropic, OpenAI's healthcare push fans the flames of privacy unrest, 1月 16, 2026にアクセス、 [https://m.economictimes.com/tech/technology/anthropic-openais-healthcare-push-fans-the-flames-of-privacy-unrest/articleshow/126479485.cms](https://m.economictimes.com/tech/technology/anthropic-openais-healthcare-push-fans-the-flames-of-privacy-unrest/articleshow/126479485.cms)  
19. Hypocrisy of Ethical claims. Claude's recent Consumer Terms and Privacy Policy updates, 1月 16, 2026にアクセス、 [https://erkansaka.net/2025/09/01/claude-ai-privacy-policy-reversal-2025/](https://erkansaka.net/2025/09/01/claude-ai-privacy-policy-reversal-2025/)  
20. Generative AI – IP cases and policy tracker | Mishcon de Reya, 1月 16, 2026にアクセス、 [https://www.mishcon.com/generative-ai-intellectual-property-cases-and-policy-tracker](https://www.mishcon.com/generative-ai-intellectual-property-cases-and-policy-tracker)  
21. Analysis: The success of Generative AI in the book sector is based on theft \- EWC, 1月 16, 2026にアクセス、 [https://europeanwriterscouncil.eu/gai-is-based-on-theft/](https://europeanwriterscouncil.eu/gai-is-based-on-theft/)  
22. The Anthropic Copyright Settlement: Dissecting the Anatomy of a Landmark AI Case, 1月 16, 2026にアクセス、 [https://www.bhfs.com/insight/the-anthropic-copyright-settlement-dissecting-the-anatomy-of-a-landmark-ai-case/](https://www.bhfs.com/insight/the-anthropic-copyright-settlement-dissecting-the-anatomy-of-a-landmark-ai-case/)  
23. Why Anthropic's Copyright Settlement Changes the Rules for AI Training | Jones Walker LLP, 1月 16, 2026にアクセス、 [https://www.joneswalker.com/en/insights/blogs/ai-law-blog/why-anthropics-copyright-settlement-changes-the-rules-for-ai-training.html?id=102l0z0](https://www.joneswalker.com/en/insights/blogs/ai-law-blog/why-anthropics-copyright-settlement-changes-the-rules-for-ai-training.html?id=102l0z0)  
24. Anthropic's Copyright Settlement: Lessons for AI Developers and Deployers, 1月 16, 2026にアクセス、 [https://www.bipc.com/anthropic%E2%80%99s-copyright-settlement-lessons-for-ai-developers-and-deployers](https://www.bipc.com/anthropic%E2%80%99s-copyright-settlement-lessons-for-ai-developers-and-deployers)  
25. Anthropic's Landmark Copyright Settlement: Implications for AI Developers and Enterprise Users | Insights | Ropes & Gray LLP, 1月 16, 2026にアクセス、 [https://www.ropesgray.com/en/insights/alerts/2025/09/anthropics-landmark-copyright-settlement-implications-for-ai-developers-and-enterprise-users](https://www.ropesgray.com/en/insights/alerts/2025/09/anthropics-landmark-copyright-settlement-implications-for-ai-developers-and-enterprise-users)  
26. What to Know About the $1.5 Billion Bartz v. Anthropic Settlement | Copyright Alliance, 1月 16, 2026にアクセス、 [https://copyrightalliance.org/participating-bartz-v-anthropic-settlement/](https://copyrightalliance.org/participating-bartz-v-anthropic-settlement/)  
27. Amazon and Anthropic deepen strategic collaboration, 1月 16, 2026にアクセス、 [https://www.aboutamazon.com/news/aws/amazon-invests-additional-4-billion-anthropic-ai](https://www.aboutamazon.com/news/aws/amazon-invests-additional-4-billion-anthropic-ai)  
28. Anthropic Opens Door to Gulf Investment — and a New Era of AI Power Politics, 1月 16, 2026にアクセス、 [https://www.techrepublic.com/article/news-anthropic-opens-door-to-gulf-state-investment/](https://www.techrepublic.com/article/news-anthropic-opens-door-to-gulf-state-investment/)  
29. Leaked memo: Dario Amodei told staff Anthropic plans to seek UAE and Qatar funding, likely enriching “dictators”, and says a “no bad person” rule is impractical (Kylie Robison/Wired) \- Techmeme, 1月 16, 2026にアクセス、 [https://www.techmeme.com/250721/p31](https://www.techmeme.com/250721/p31)  
30. IPOs 2026: Will Anthropic, SpaceX and OpenAI rock the stock market? \- Trending Topics, 1月 16, 2026にアクセス、 [https://www.trendingtopics.eu/ipos-2026-will-anthropic-spacex-and-openai-rock-the-stock-market/](https://www.trendingtopics.eu/ipos-2026-will-anthropic-spacex-and-openai-rock-the-stock-market/)  
31. Anthropic, OpenAI Ignite Preparations for IPO; SpaceX Seeking I-Banks for Listing: WireUS Stocks \- Global News Content \- AASTOCKS.com, 1月 16, 2026にアクセス、 [https://www.aastocks.com/en/usq/news/comment.aspx?source=AAFN\&id=NOW.1496236\&catg=4](https://www.aastocks.com/en/usq/news/comment.aspx?source=AAFN&id=NOW.1496236&catg=4)  
32. Agentic Misalignment: How LLMs could be insider threats \- Anthropic, 1月 16, 2026にアクセス、 [https://www.anthropic.com/research/agentic-misalignment](https://www.anthropic.com/research/agentic-misalignment)  
33. Introducing Labs \- Anthropic, 1月 16, 2026にアクセス、 [https://www.anthropic.com/news/introducing-anthropic-labs](https://www.anthropic.com/news/introducing-anthropic-labs)  
34. Anthropic Study Finds Most Workers Use AI Daily, but 69 Percent Hide It at Work, 1月 16, 2026にアクセス、 [https://www.finalroundai.com/blog/anthropic-interviewer-study](https://www.finalroundai.com/blog/anthropic-interviewer-study)  
35. How AI Is Transforming Work at Anthropic, 1月 16, 2026にアクセス、 [https://www.anthropic.com/research/how-ai-is-transforming-work-at-anthropic](https://www.anthropic.com/research/how-ai-is-transforming-work-at-anthropic)  
36. Anthropic Economic Index: new building blocks for understanding AI use, 1月 16, 2026にアクセス、 [https://www.anthropic.com/research/economic-index-primitives](https://www.anthropic.com/research/economic-index-primitives)  
37. Anthropic Economic Index report: Economic primitives, 1月 16, 2026にアクセス、 [https://www.anthropic.com/research/anthropic-economic-index-january-2026-report](https://www.anthropic.com/research/anthropic-economic-index-january-2026-report)