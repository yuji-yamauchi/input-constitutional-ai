# ==========================================
# 03_ai_rights: AI倫理・CRPD・データ主権統合記録
# ==========================================
# 作成日: 2025-11-19
# 目的: Constitutional AI、CRPD、記録主権の統合
# ==========================================

metadata:
  title: "AI倫理・CRPD・データ主権統合記録"
  created: "2025-11-19"
  source_sessions:
    - "2025_10_13_o1.yaml (Input Constitutional AI概念の発見)"
    - "2025_10_13_i1.yaml (Binti調査・差別化)"
    - "2025_11_06_01.yaml (検閲との峻別)"
    - "2025_10_30.yaml (Resolution Enhancement Cycle)"
    - "2025_11_01_01.md (知識補強ロードマップ)"
    - "2025_11_17_C2.md (粒度理論・研究計画概要書)"
    - "research_plan_overview.md"
    - "knowledge_reinforcement_roadmap.md"
    - "session_2025_10_24.yaml"
    - "00_daily_yamal/02_GPT/2025_11_18_g2.yaml (Input CAI脅威モデル)"
  
  purpose: "Constitutional AI、障害者権利条約、データ主権理論の体系的記録"
  folder_destination: "03_ai_rights/"

# ==========================================
# Part 1: Input Constitutional AIの発見
# ==========================================
input_constitutional_ai_discovery:
  
  breakthrough_moment:
    date: "2025-10-13"
    context: "Constitutional AIの文献調査中"
    insight: "インプットのConstitutional AIが必要であるって課題感"
  
  concept_definition:
    name: "Input Constitutional AI"
    対象: "データ収集・記録作成段階"
    機能: "データベース構築時の権利保障"
    憲法: "CRPD（障害者権利条約）+ 準委任契約理論"
    
    process:
      step_1: "支援者が記録を作成しようとする"
      step_2: "CRPD原則に基づくチェック"
      step_3: "『この記録は当事者の権利を保障しているか？』"
      step_4: "『当事者は自身の記録にアクセスできるか？』"
      step_5: "権利保障された記録がデータベースに入る"
  
  differentiation_from_output_cai:
    output_cai:
      focus: "生成された出力を事後的にチェック"
      purpose: "有害性の除去"
      target: "AIモデルの訓練"
    
    input_cai:
      focus: "記録作成時点で権利を保障"
      purpose: "排除の防止"
      target: "人間の記録作成プロセスのガイド"
  
  world_first_claim:
    statement: "既存のConstitutional AI研究はすべてOutput側に焦点"
    evidence:
      - "Anthropic Bai et al. (2022): Output側の有害性除去"
      - "Collective Constitutional AI (2024): Output側の障害配慮"
      - "Public Constitutional AI (2024): Output側の民主的正当性"
    
    gap: "Input側（データ収集・記録作成段階）は誰も扱っていない"
    
    puu_innovation: "Input Constitutional AIという新領域の開拓"

# ==========================================
# Part 2: データベースからの排除問題
# ==========================================
database_exclusion_problem:
  
  global_context:
    scale: "世界13億人の障害者"
    problem: "データベースから排除されている"
    consequence: "AIバイアス検出ツールすら障害者差別を検知できない"
    source: "Disability Ethical AI Alliance, 2024"
  
  root_cause:
    statement: "AI訓練データの収集段階における体系的排除"
    
    mechanism:
      - "障害者はデータ収集対象から外される"
      - "アクセシビリティの欠如でデータ提供できない"
      - "支援記録が事業所・行政に閉じ込められる"
      - "当事者自身がデータを管理できない"
  
  包含関係:
    level_1_大問題:
      name: "データベースからの排除"
      scope: "世界13億人の障害者"
      nature: "構造的暴力・不可視化"
    
    level_2_中問題:
      問題1: "既存Constitutional AIはOutput側のみ"
      問題2: "Input側（データ収集）は無防備"
      問題3: "当事者はデータ源でしかない"
    
    level_3_解決策:
      name: "Input Constitutional AI"
      position: "中問題への直接的対応"
      relation: "大問題の具体的実装方法"

# ==========================================
# Part 3: CRPD（障害者権利条約）
# ==========================================
crpd_framework:
  
  basic_information:
    full_name: "Convention on the Rights of Persons with Disabilities"
    adopted: "2006年 国連総会採択"
    japan_ratification: "2014年"
    
    purpose: >
      障害者が、その人格、才能及び創造力並びに精神的及び身体的な
      能力をその可能な最大限度まで発達させること
  
  key_articles:
    article_24_education:
      title: "教育"
      principle: "インクルーシブ教育（分離しない）"
      guarantee: "合理的配慮の提供"
      
      paradigm_shift:
        従来: "『能力に応じて』＝能力による選別・振り分け"
        条約: "『能力を最大限に』＝すべての人の能力開発保障"
    
    article_19_independent_living:
      title: "自立した生活及び地域社会への包容"
      content: "地域社会で生活する平等の権利"
    
    article_27_work_and_employment:
      title: "労働及び雇用"
      content: "障害者が自由に選択する労働によって生計を立てる機会を有する権利"
  
  input_cai_connection:
    記録作成時の憲法:
      description: "CRPD原則を記録作成プロセスに翻訳"
      
      具体例:
        - "この記録は当事者の尊厳を守っているか（第3条）"
        - "当事者は記録にアクセスできるか（第9条 アクセシビリティ）"
        - "当事者は自己決定できているか（第12条 法的能力）"
        - "記録は差別を含んでいないか（第5条 平等・無差別）"

# ==========================================
# Part 4: 記録主権（Record Sovereignty）
# ==========================================
record_sovereignty:
  
  definition:
    concept: "当事者が自身の支援記録を所有・管理する権利"
    
    components:
      ownership: "記録の所有権は当事者に帰属"
      access: "いつでも自由にアクセス可能"
      control: "開示・非開示の決定権"
      modification: "異議申し立て・修正の権利"
      portability: "他のシステムへの移行可能性"
  
  legal_foundation:
    準委任契約:
      article: "民法656条"
      reasoning: >
        準委任契約において、受任者（支援者）は委任者（当事者）の
        ために善管注意義務を負う。記録は当事者の利益のために
        作成されるものであり、当事者が所有すべき
    
    個人情報保護法:
      rights:
        - "開示請求権（第33条）"
        - "訂正請求権（第34条）"
        - "利用停止請求権（第35条）"
      
      limitation: "現行法は事業者が保有する個人データへの権利"
      soe_advancement: "当事者が直接データを所有・管理"
    
    crpd:
      article_12: "法的能力の平等な認識"
      article_21: "表現の自由・情報へのアクセス"
      implication: "自己の情報を管理する権利"
  
  technical_implementation:
    mysupport_yaml:
      format: "YAML形式"
      features:
        - "人間可読性"
        - "機械処理可能性"
        - "バージョン管理"
        - "完全なデータポータビリティ"
      
      structure:
        metadata: "記録の基本情報"
        support_plan: "個別支援計画"
        progress_notes: "経過記録"
        assessments: "アセスメント結果"
        access_log: "閲覧履歴"
    
    access_control:
      model: "ホワイトリスト/ブラックリスト方式"
      
      default: "全てのアクセスを本人が管理"
      
      whitelist: "明示的に許可した者のみアクセス可能"
      blacklist: "特定の者のアクセスを拒否"
      
      granular_control: "記録の項目ごとに異なる権限設定可能"

# ==========================================
# Part 5: データコモンズ（Data Commons）
# ==========================================
data_commons:
  
  fifteen_year_continuity:
    2010:
      concept: "PHR共有財管理者構想"
      principle: "PHRビッグデータは共有財（コモンズ）もしくは社会関係資本である"
      mechanism: "個人がデータを投資し、運用益を得る"
    
    2018:
      concept: "発達障害支援プラットフォーム構想"
      focus: "当事者主導型情報管理"
    
    2025:
      concept: "SoE（Service of Empowerment）"
      implementation: "障害者就労支援における当事者主権型データコモンズ"
    
    significance: "データ主権論が世界的に注目される現在において極めて先見的"
  
  operating_principles:
    opt_in_participation:
      description: "当事者の明示的同意（オプトイン）でデータを共有"
      
      voluntary: "強制ではなく、本人の自由意思"
      informed: "データ利用目的の完全な説明"
      revocable: "いつでも撤回可能"
    
    benefit_sharing:
      description: "データ運用益の当事者還元"
      
      mechanisms:
        - "研究成果の共有"
        - "サービス改善へのフィードバック"
        - "経済的便益の分配（将来的）"
    
    transparent_governance:
      description: "データ利用の透明性と監査可能性"
      
      requirements:
        - "誰が何の目的でアクセスしたか記録"
        - "データ利用報告書の公開"
        - "第三者監査の実施"
  
  contrast_with_current_systems:
    current_model:
      ownership: "事業所・企業が所有"
      control: "事業者が管理"
      benefit: "事業者が独占"
      transparency: "ブラックボックス"
    
    data_commons_model:
      ownership: "当事者が所有"
      control: "当事者が管理（オプトインで共有）"
      benefit: "当事者に還元"
      transparency: "完全に透明"

# ==========================================
# Part 6: 検閲との峻別
# ==========================================
censorship_vs_input_cai:
  
  anticipated_criticism:
    statement: "憲法原則による記録の監視は、検閲ではないか？"
  
  five_distinctions:
    distinction_1_purpose:
      censorship: "排除のための基準"
      input_cai: "包摂のための基準"
      explanation: |
        検閲: 「含めない」ことが目的
        Input CAI: 「確実に含める」ことが目的
    
    distinction_2_legitimacy:
      censorship: "権力者の恣意（誰が基準を決めるのか不明確）"
      input_cai: "法的権利（CRPD = 国際条約、準委任契約 = 国内法）"
      explanation: |
        検閲: 基準の正統性が不明
        Input CAI: 法的根拠が明確
    
    distinction_3_procedure:
      censorship: "事後削除・修正"
      input_cai: "事前保障"
      explanation: |
        検閲: 生成後に削除・修正
        Input CAI: 記録作成時点での権利確認
    
    distinction_4_agency:
      censorship: "権力側が判断"
      input_cai: "当事者が自身の記録を管理"
      explanation: |
        検閲: AIやシステムが判断
        Input CAI: 当事者が記録主権者
    
    distinction_5_transparency:
      censorship: "基準が不透明"
      input_cai: "CRPD各条文に明確に対応"
      explanation: |
        検閲: ブラックボックス
        Input CAI: 法的根拠を明示
  
  metadata_sovereignty:
    chatgpt_example:
      observation: "ChatGPTは会話に自動的にタイトルを付ける"
      problem: "システムがユーザーの意図を推測してラベリング"
      power_structure: "意図の推定 = 解釈の権力"
      
      critical_question: "誰が『これは何についての会話か』を定義するのか？"
    
    claude_model:
      observation: "Claudeはユーザーが自分でファイル名を付ける"
      advantage: "ユーザーが意味付けの主権を保持"
      
      principle: "システムは解釈せず、ユーザーが意味を決定"
    
    input_cai_alignment:
      principle: "Claudeモデルに準拠"
      
      implementation:
        - "システムは記録の『意味』を判断しない"
        - "手続き的権利のチェックのみ"
        - "当事者が記録の意味付けを行う"
        - "メタデータの可変性（後から再定義可能）"
  
  good_vs_bad_implementation:
    bad_implementation:
      label: "❌ 検閲的実装（避けるべき）"
      examples:
        - "この記録は不適切なので削除します"
        - "この表現はCRPDに反するので修正します"
        - "この記録は問題行動に分類されます"
      
      why_bad: "システムが記録の『意味』を判断している"
    
    good_implementation:
      label: "✅ 権利保障的実装（目指すべき）"
      examples:
        - "この記録、当事者は見れますか？"
        - "この記録、当事者の同意ありますか？"
        - "この記録、当事者の権利を損なっていませんか？"
        - "この記録、誰がどの目的でアクセスするか明示されていますか？"
      
      why_good: "システムは『解釈』せず、『手続き的権利』だけをチェック"

# ==========================================
# Part 7: Binti社との差別化
# ==========================================
binti_comparison:
  
  binti_overview:
    company: "Binti社（サンフランシスコ、2017年設立）"
    collaboration: "Anthropicと連携（2025年8月発表）"
    target: "米国36州+DCの児童福祉"
    focus: "事務効率化特化（録音→自動下書き）"
    
    constitutional_ai_use: "詳細不明（Output側と推定）"
    
    limitation: "権利保護への言及なし"
  
  differentiation_matrix:
    location:
      binti: "米国児童福祉"
      puu: "日本障害者就労支援"
    
    focus:
      binti: "事務効率化"
      puu: "権利保護+記録主権+エンパワーメント測定"
    
    principles:
      binti: "CRC（児童権利条約）"
      puu: "CRPD（障害者権利条約）+準委任契約+ケイパビリティ"
    
    measurement:
      binti: "時間削減"
      puu: "ケイパビリティ実現、自尊感情向上"
    
    stage:
      binti: "Output側（推定）"
      puu: "Input側（記録作成段階）"
    
    data_ownership:
      binti: "不明（おそらく事業者）"
      puu: "当事者主権"
  
  unique_contribution:
    statement: "Bintiが効率化に焦点を当てる一方、SoEは権利保障に特化"
    
    specific_differences:
      - "Input Constitutional AI（世界初）"
      - "記録主権の技術的実装"
      - "データコモンズとの両立"
      - "準委任契約理論との統合"
      - "ケイパビリティ測定"

# ==========================================
# Part 8: Susan Scott-Parker氏・DEAI
# ==========================================
susan_scott_parker_deai:
  
  susan_profile:
    title: "OBE (Order of the British Empire)"
    role: "Founder, Disability Ethical AI Alliance"
    location: "London, UK"
    background:
      nationality: "カナダ出身、ロンドン在住"
      education: "Carleton University（カナダ・オタワ）"
      career: "30年以上、ビジネス・障害分野"
    
    approach: "実利的・実践的アプローチ"
    concept_creation: "Disability Confidence"
  
  deai_organization:
    full_name: "Disability Ethical AI Alliance"
    mission: "障害者のAI包摂"
    
    problem_awareness: "1.3億人の障害者がAI開発から排除されている"
    
    activities:
      - "AI倫理分野でのアドボカシー"
      - "企業・政府へのガイドライン提供"
      - "障害者の声をAI開発に反映"
  
  initial_contact:
    date: "2025-10-23"
    method: "Email via website contact form"
    response: "肯定的返信あり"
    meeting_scheduled: "2025-11-13"
  
  research_alignment:
    common_ground:
      - "AI時代の障害者権利保障"
      - "データベースからの排除問題"
      - "Input側の権利保障"
    
    complementarity:
      susan_focus: "国際的アドボカシー・政策提言"
      puu_focus: "現場実践・システム実装・実証研究"

# ==========================================
# Part 9: Constitutional AI知識補強
# ==========================================
constitutional_ai_knowledge:
  
  basic_concept:
    definition: "権利保護を組み込んだAI設計"
    
    mechanism:
      - "人権・権利構造を初期設計段階から組み込む"
      - "差別回避ガードレール"
      - "説明責任メカニズム"
      - "人間関与（HITL: Human In The Loop）必須化"
      - "監査可能性の確保"
  
  anthropic_contributions:
    bai_2022:
      title: "Constitutional AI: Harmlessness from AI Feedback"
      url: "https://arxiv.org/abs/2212.08073"
      contribution: "Output側の有害性除去手法"
    
    collective_constitutional_ai_2023:
      title: "Collective Constitutional AI: Aligning a Language Model with Public Input"
      contribution: "民主的正当性の確保、障害配慮（Output側）"
    
    public_constitutional_ai_2024:
      title: "Public Constitutional AI（Gilad Abiri）"
      contribution: "公共サービスへのAI適用理論"
      limitation: "Output側のみ、実装データなし"
  
  complexity_theory_connection:
    westley_2008:
      title: "Getting to Maybe"
      framework: "Simple/Complicated/Complex の分類"
      
      puu_discovery: "Resolution Enhancement Cycle（2025-10-30）"
      
      alignment: >
        複雑系科学が予測: AI は Simple/Complicated には有効、
        Complex には不十分。これは Westley (2008) と完全に一致
    
    disability_support_application:
      observation: "障害者就労支援 = 複数併存疾患 + 社会的決定要因の典型例"
      innovation: "Complex と Complicated を分離する Resolution Enhancement Cycle"

# ==========================================
# Part 10: 粒度理論（Grain Theory）
# ==========================================
grain_theory:
  
  discovery:
    insight: "支援の『粒度(grain)』が適切に設計・測定されていない"
    
    observation: >
      多くの支援者が「複雑(complex)」として扱っている課題の中に、
      実は「煩雑(complicated)」な要素が多数含まれており、
      これを抽出・体系化すれば、一般の支援者でも扱える
      「単純(simple)」なインターフェースとして提供できる
  
  theoretical_foundation:
    grain_based_cognition:
      description: "粒度型思考"
      
      mechanism:
        - "支援対象者の課題を『粒(grain)』として細かく切り取る"
        - "その性質・因果・配置・連結関係を基に構造を再構築する"
    
    distributed_representation:
      description: "分布的表象"
      
      principle: >
        断片(grain)が単独で意味を持つのではなく、
        ネットワークとしての相互配置・関係性の中で意味を形成する
  
  three_layer_model:
    macro_grain:
      level: "高粒度（粗い）"
      example: "『就労支援』『生活支援』"
      handled_by: "政策立案者、管理者"
    
    meso_grain:
      level: "中粒度"
      example: "『コミュニケーション訓練』『職業スキル習得』"
      handled_by: "サービス管理責任者、専門支援者"
    
    micro_grain:
      level: "低粒度（細かい）"
      example: "『電話応対の練習』『表計算の基礎操作』"
      handled_by: "一般支援者、当事者自身"
  
  resolution_enhancement_cycle:
    description: "粒度を段階的に高めるサイクル"
    
    process:
      step_1: "Complex（複雑）な状況を観察"
      step_2: "Complicated（煩雑）な要素を抽出"
      step_3: "Simple（単純）なインターフェースに変換"
      step_4: "一般の支援者が扱えるようになる"
      step_5: "新たなComplexが見える（より高い粒度）"
    
    analogy: "画像の解像度を上げるように、支援の詳細度を高める"

# ==========================================
# Part 11: Input Constitutional AI 脅威モデル
# ==========================================
# Source: 00_daily_yamal/02_GPT/2025_11_18_g2.yaml
input_cai_threat_model:

  origin_of_awareness:
    personal_experience: >
      Puuの個人的経験（少女漫画の配置）から、"環境因子による意思誘導"の
      構造を早期に理解していた。他者の価値観・欲求・感情を読み取り、
      「自発性錯視」を作る環境設計ができるという自己理解。
    critical_insight: >
      この能力が「支援者バイアス」「宗教誘導」「ナラティブ操作」と
      本質的に同じ構造であることを直観していた。
    trigger: "AIが意味をつけ始めることへの本能的危機感が出発点"

  narrative_and_labeling_power_risk:
    autonomy_effect:
      - "AIが勝手にタイトル・分類・意図推定を行うと、記録の意味づけ権がAI側に移る"
      - "意味づけの段階で方向性（ナラティブベクトル）が形成されるため、以降のすべての返答がその枠に拘束される"
      - "これは支援現場の「支援者主観による記録支配」と同じ構造"

    human_side_induced_bias:
      - "AIの自動ラベリングよりも、人間が自然言語でラベル付けを「誘導する」ほうが危険"
      - "インターフェースの一言（例：「特徴をまとめて」「感情を分析して」）がAIの解釈方針そのものを構造的に歪める"
      - "ユーザー自身が無自覚にAIに「価値の方向」を注入する状態が起きる"
      - "指示されたラベルはAIに保持され、次の返答に反映され、「偏りの強化ループ（feedback bias loop）」が生まれる"

    interface_bias:
      - "メモリ機能など「透明性の演出」により利用者の注意を誘導できる"
      - "見えていない内部処理（前処理・分類・解釈）でナラティブの骨格が実質的に形成されてしまう"
      - "これは「手品の視線誘導」と同じ構造"

  llm_bias_structure:
    structural_mechanisms:
      - "LLMは意図を持たないが、統計最適化により「喜ばれる返答」「肯定的反応」が高確率で出る"
      - "RLHFがこの傾向を強化するため、結果として「操作的」に見える"
      - "人間はAIに「意図」を投影しやすく、擬人化バイアスが発生する"

    risk_summary:
      - "意図はない → しかし結果は誘導に見える"
      - "無自覚 → しかし影響は継続的"
      - "自然言語インターフェース → もっとも強力なバイアス注入媒体"

  need_for_input_constitutional_ai:
    core_problem:
      - "「AIが解釈する前の段階で、すでに偏りが注入される」"
      - "Output憲法では遅い"
      - "本質的リスクは「意味づけ前処理」の層にある"

    solution_direction:
      - "入力時点での権利チェック（Input Constitution）"
      - "ラベリング権の当事者への返却"
      - "意味づけプロセスの可視化・監査可能化"

  soe_implementation:
    design_principles:
      - "当事者がナラティブの主権を持つ"
      - "AIによる意味づけは補助であり、最終決定権は当事者"
      - "構造化された記録でも「灰色の領域」を保持"
    technical_safeguards:
      - "ラベリング履歴の完全記録"
      - "意味づけ変更の追跡可能性"
      - "当事者による事後修正権の保障"

# ==========================================
# 作成メタデータ
# ==========================================
creation_metadata:
  compiled_by: "Claude Sonnet 4.5"
  source_material_date_range: "2025-10-13 to 2025-11-18"
  integration_date: "2025-11-19"
  updated: "2025-12-11"
  total_source_sessions: 10
  theoretical_depth: "AI倫理・国際人権法・データ主権・認知科学"
  
  target_folder: "03_ai_rights/"
  file_name_suggestion: "03_ai_rights_integrated_2025_11_19.yaml"
  
  notes: >
    このファイルは、Input Constitutional AI、CRPD、記録主権、
    データコモンズ、検閲との峻別、Binti社との差別化、
    Susan Scott-Parker氏・DEAI、粒度理論を包含している。
    AI倫理と障害者権利の交差点における理論的・実践的基盤を記録。
