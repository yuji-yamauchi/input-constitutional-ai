# =============================================================================
# Co-LLM Session Protocol (共同LLMセッションプロトコル)
# =============================================================================
# Source: 00_daily_yamal/01_Claude/2025_12_25_co_llm_session_analysis_report.yaml
#         + 00_daily_yamal/01_Claude/2025_12_25_session_final.yaml
# Extracted: 2026-01-04
# =============================================================================

meta:
  version: "1.0"
  last_updated: "2026-01-04"
  sources:
    - "2025_12_25_co_llm_session_analysis_report.yaml"
    - "2025_12_25_session_final.yaml"
  extracted_by: "Claude Code (Opus 4.5)"

# =============================================================================
# Executive Summary
# =============================================================================
executive_summary: |
  「専門家×LLM×当事者」三者構造の支援方法論。
  LLM単独セッションの依存リスクと、専門家×当事者の直撃リスクを同時に解決する。
  スキーマ構築プロトコルにより、支援の質と再現性を向上。

# =============================================================================
# Session Structure Comparison
# =============================================================================
session_structures:

  structure_a_llm_solo:
    name: "LLM単独セッション"
    configuration: "LLM ←→ 当事者"
    strengths:
      - "心理的安全性が高い（AIは評価しない）"
      - "24時間いつでも利用可能"
      - "『褒め』『共感』が豊富で安心感を提供"
    weaknesses:
      - "LLMは基本的に肯定・共感に傾く"
      - "『甘さ』への指摘ができない"
      - "依存構造を生みやすい"
      - "視点の高さを提供できない"
    dependency_risk_mechanism: |
      1. LLMが「いいですね」「素晴らしいですね」を連発
      2. 当事者が「認められた」と感じる
      3. 心地よさから繰り返し利用
      4. 批判・指摘がないため成長機会を逃す
      5. LLMとの対話が「逃げ場」になる

  structure_b_specialist_client:
    name: "専門家×当事者 二者セッション"
    configuration: "専門家 ←→ 当事者"
    strengths:
      - "構造的視点の直接提供"
      - "『甘さ』への指摘が可能"
      - "現実の厳しさを伝えられる"
    weaknesses:
      - "専門家の視点の高さが直撃する"
      - "当事者が『評価されている』と感じやすい"
      - "防衛的反応を引き起こしやすい"
      - "関係性が壊れるリスク"
    direct_hit_problem: |
      専門家の指摘が「直撃」することで、
      当事者が傷つく→防衛的になる→関係性悪化→支援継続しない

  structure_c_three_way:
    name: "専門家×LLM×当事者 三者セッション"
    configuration: "専門家 ←→ LLM ←→ 当事者"
    strengths:
      - "LLMが緩衝役として機能"
      - "専門家の指摘がLLMを通じて緩和される"
      - "当事者は心理的安全を保ちながら深い洞察を受け取れる"
      - "用語のレイヤー翻訳をLLMが担当"
      - "依存構造が生まれにくい（専門家が監視）"
    weaknesses:
      - "セットアップに時間がかかる"
      - "三者のコミュニケーションコストが増加"
      - "専門家のリアルタイム監視が必要"

# =============================================================================
# Role Distribution in Three-Way Session
# =============================================================================
role_distribution:
  specialist:
    primary_functions:
      - "構造的リスクの指摘"
      - "補助線の提示"
      - "本質的な問いかけ"
      - "LLMの『褒め』への突っ込み"
      - "依存構造の監視"
    offloaded_to_llm:
      - "基本的なヒアリング"
      - "用語のレイヤー翻訳"
      - "感情的緩衝"

  llm:
    primary_functions:
      - "感情と構造の翻訳"
      - "用語のレイヤー調整"
      - "選択肢の整理・言語化"
      - "心理的安全の緩衝材"
    monitored_by_specialist:
      - "過度な肯定の抑制"
      - "依存構造の芽の摘み取り"

  client:
    primary_functions:
      - "自己感覚の言語化に集中"
      - "緩衝された情報の受け取り"
    benefits:
      - "直撃を避けられる"
      - "評価されている感覚が軽減"

# =============================================================================
# Schema Building Protocol
# =============================================================================
schema_building_protocol:
  concept: |
    当事者×LLMの事前セッション（30分×複数回）を通じて
    当事者の認知・言語特性を測定し、YAMLスキーマとして構造化。
    このスキーマを共同セッション開始時に読み込ませることで、
    LLMの翻訳精度を向上させる。

  phase_1_measurement_sessions:
    frequency: "30分 × 3-5回"
    configuration: "LLM ←→ 当事者（専門家不在）"
    session_themes:
      - "自己紹介・背景"
      - "困りごとの言語化"
      - "選択肢の検討"
      - "過去の経験"
      - "将来の希望"
    auto_extracted_parameters:
      - vocabulary_level: ["基礎", "標準", "専門"]
      - reading_comprehension: ["具体例必要", "抽象OK", "高度な抽象OK"]
      - emotional_triggers: "list"
      - preferred_explanation_style: ["比喩", "論理", "事例", "数値"]
      - decision_making_style: ["直感", "熟慮", "外部参照", "回避"]

  phase_2_schema_output:
    filename_format: "persona_schema_[name]_[date].yaml"

  phase_3_schema_injection:
    procedure:
      - "共同セッション開始前にスキーマYAMLを読み込ませる"
      - "LLMにスキーマに基づく翻訳・説明を指示"
      - "専門家は構造提示に集中"
      - "セッション後にスキーマを更新"

# =============================================================================
# SoE Connection
# =============================================================================
soe_connection:
  principle: "本人主権型アセスメントの実装"

  traditional_assessment:
    flow: "支援者 → 当事者を『測定』→ 支援者が『判定』"
    problem: "当事者は客体として扱われる"

  schema_building_assessment:
    flow: "当事者 × LLM → 自然な対話で『抽出』→ 双方が参照可能"
    benefits:
      - "測定されている感覚が薄い"
      - "結果が『自分のため』に使われる実感"
      - "アセスメントが『武器』ではなく『道具』になる"

  consent_validity_enhancement: |
    スキーマ構築プロセス自体が：
    - 選択肢を知る機会を提供
    - 自己理解を深める
    - 有効な同意の基盤を作る

    これにより「未必の故意」リスクを低減

# =============================================================================
# Key Formula
# =============================================================================
key_formula: |
  三者構造 + スキーマ構築 + 等価交換原則 = SoE実装プロトコル

# =============================================================================
# Tada Principle (ただより高いものはなし)
# =============================================================================
tada_principle:
  statement: "ただより高いものはなし"

  dual_meaning:
    negative: "無料の支援は実は搾取"
    positive: "透明な等価交換として設計すれば相互投資"

  application:
    client_provides:
      - "時間と経験"
      - "データ（貴重なN）"
      - "スキーマ構築への協力"
    specialist_provides:
      - "専門知識と構造的洞察"
      - "最適化された支援"

  transparency_requirement: |
    「あなたのデータは研究に使います」
    「その代わり支援の質を上げます」
    明示的な合意 = 有効な同意
    これが「未必の故意」を回避する構造
